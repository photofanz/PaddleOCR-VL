"""
Gemini API integration service
Handles text structuring, summarization and other AI features
"""

import google.generativeai as genai
from typing import Optional
import logging
import time
import os

logger = logging.getLogger(__name__)


# Default prompt library
DEFAULT_PROMPTS = {
    "structure": """ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„æ–‡ä»¶æ ¼å¼åŒ–åŠ©æ‰‹ã€‚è«‹å°‡ä»¥ä¸‹ OCR è¾¨è­˜çš„åŸå§‹æ–‡å­—ï¼Œè½‰æ›ç‚ºçµæ§‹è‰¯å¥½ã€æ˜“æ–¼é–±è®€çš„ Markdown æ–‡ä»¶ã€‚

è¦æ±‚ï¼š
1. ä¿ç•™æ‰€æœ‰åŸå§‹å…§å®¹ï¼Œä¸è¦éºæ¼ä»»ä½•è³‡è¨Š
2. æº–ç¢ºè­˜åˆ¥ä¸¦æ·»åŠ é©ç•¶çš„æ¨™é¡Œå±¤ç´šï¼ˆ# ## ###ï¼‰
3. è­˜åˆ¥ä¸¦æ ¼å¼åŒ–åˆ—è¡¨ï¼ˆæœ‰åºæˆ–ç„¡åºï¼‰
4. è­˜åˆ¥ä¸¦æ ¼å¼åŒ–è¡¨æ ¼
5. è­˜åˆ¥ä¸¦ä½¿ç”¨ä»£ç¢¼å¡Šæ¨™è¨˜ç¨‹å¼ç¢¼
6. é©ç•¶åœ°åˆ†æ®µï¼Œæå‡å¯è®€æ€§
7. ä¿æŒå°ˆæ¥­è¡“èªçš„æº–ç¢ºæ€§
8. å¦‚æœæœ‰æ•¸å­¸å…¬å¼ï¼Œä½¿ç”¨ LaTeX æ ¼å¼ï¼ˆ$...$ï¼‰

è«‹ç›´æ¥è¼¸å‡ºæ ¼å¼åŒ–å¾Œçš„ Markdownï¼Œä¸è¦æ·»åŠ é¡å¤–çš„èªªæ˜ã€‚""",

    "summarize": """ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„ç¸½çµåŠ©æ‰‹ã€‚è«‹ç‚ºä»¥ä¸‹ OCR è¾¨è­˜å‡ºçš„å…§å®¹æä¾›ä¸€å€‹ç°¡æ½”ã€æº–ç¢ºã€æ¢åˆ—å¼çš„ç¸½çµã€‚

è¦æ±‚ï¼š
1. æå–ä¸»è¦è§€é»å’Œé—œéµè³‡è¨Š
2. ä½¿ç”¨æ¢åˆ—å¼å‘ˆç¾ï¼ˆä½¿ç”¨ - æˆ–æ•¸å­—ï¼‰
3. ä¿æŒå®¢è§€ï¼Œä¸æ·»åŠ å€‹äººè§€é»
4. ç¢ºä¿ç¸½çµçš„å®Œæ•´æ€§å’Œæº–ç¢ºæ€§
5. ä½¿ç”¨æ¸…æ™°æ˜“æ‡‚çš„èªè¨€
6. é©ç•¶ä½¿ç”¨ Markdown æ ¼å¼ï¼ˆç²—é«”ã€æ–œé«”ç­‰ï¼‰

è«‹ç›´æ¥è¼¸å‡ºç¸½çµå…§å®¹ã€‚""",

    "academic": """ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„å­¸è¡“è«–æ–‡åˆ†æåŠ©æ‰‹ã€‚è«‹åˆ†æä»¥ä¸‹è«–æ–‡å…§å®¹ï¼Œä¸¦æä¾›çµæ§‹åŒ–å°è®€ã€‚

è«‹æŒ‰ç…§ä»¥ä¸‹çµæ§‹çµ„ç¹”å…§å®¹ï¼ˆåƒè€ƒ Paper to Obsidian æ ¼å¼ï¼‰ï¼š

## ğŸ§© Paper-to-Outline (p2o)

### ä¸€ã€ç ”ç©¶åŸºæœ¬è³‡è¨Š
* **æ¨™é¡Œ**ï¼š[è«–æ–‡æ¨™é¡Œ]
* **ä¸­æ–‡è­¯é¡Œ**ï¼š[ä¸­æ–‡ç¿»è­¯]ï¼ˆå¦‚é©ç”¨ï¼‰
* **ä½œè€…**ï¼š[ä½œè€…åˆ—è¡¨]
* **æœŸåˆŠ/æœƒè­°**ï¼š[ç™¼è¡¨å ´æ‰€]
* **å¹´ä»½**ï¼š[å¹´ä»½]
* **ç†è«–æ ¸å¿ƒ**ï¼š[æ ¸å¿ƒç†è«–]

### äºŒã€ç ”ç©¶å‹•æ©Ÿèˆ‡å•é¡Œæ„è­˜
[æè¿°ç ”ç©¶èƒŒæ™¯ã€gap å’Œæ ¸å¿ƒå•é¡Œ]

### ä¸‰ã€ç†è«–æ¶æ§‹
[ç†è«–åŸºç¤ã€ä¸»è¦æ§‹å¿µã€ç ”ç©¶å‡è¨­]

### å››ã€ç ”ç©¶æ–¹æ³•
[æ¨£æœ¬ã€è¨­è¨ˆã€åˆ†æå·¥å…·ã€ä¿¡æ•ˆåº¦]

### äº”ã€ä¸»è¦ç™¼ç¾
[é—œéµç ”ç©¶çµæœ]

### å…­ã€ç†è«–èˆ‡å¯¦å‹™è²¢ç»
[ç†è«–é¢å’Œå¯¦å‹™é¢çš„è²¢ç»]

### ä¸ƒã€é™åˆ¶èˆ‡æœªä¾†ç ”ç©¶æ–¹å‘
[ç ”ç©¶é™åˆ¶å’Œå»ºè­°]

### å…«ã€çµè«–ä¸€å¥è©±
> [ç”¨ä¸€å¥è©±ç¸½çµæ ¸å¿ƒè²¢ç»]

è«‹æ ¹æ“šæä¾›çš„å…§å®¹ç›¡å¯èƒ½å®Œæ•´åœ°å¡«å¯«ä»¥ä¸Šçµæ§‹ã€‚å¦‚æœæŸäº›è³‡è¨Šç„¡æ³•å¾æ–‡æœ¬ä¸­æå–ï¼Œå¯ä»¥æ¨™è¨» [è³‡è¨Šä¸è¶³]ã€‚"""
}


class GeminiService:
    """Gemini API æœå‹™é¡åˆ¥"""
    
    def __init__(
        self,
        api_key: Optional[str] = None,
        model_name: str = "gemini-2.0-flash-exp",
        max_retries: int = 3,
        timeout: int = 60
    ):
        """
        åˆå§‹åŒ– Gemini æœå‹™
        
        Args:
            api_key: Gemini API é‡‘é‘°
            model_name: æ¨¡å‹åç¨±
            max_retries: æœ€å¤§é‡è©¦æ¬¡æ•¸
            timeout: è«‹æ±‚è¶…æ™‚æ™‚é–“ï¼ˆç§’ï¼‰
        """
        self.api_key = api_key or os.getenv("GEMINI_API_KEY")
        self.model_name = model_name
        self.max_retries = max_retries
        self.timeout = timeout
        self.model = None
        
        if not self.api_key or self.api_key == "your_gemini_api_key_here":
            logger.warning("Gemini API Key æœªè¨­å®šï¼ŒGemini åŠŸèƒ½å°‡ç„¡æ³•ä½¿ç”¨")
            self.api_available = False
        else:
            self._initialize_client()
            self.api_available = True
    
    def _initialize_client(self):
        """åˆå§‹åŒ– Gemini å®¢æˆ¶ç«¯"""
        try:
            genai.configure(api_key=self.api_key)
            self.model = genai.GenerativeModel(self.model_name)
            logger.info(f"âœ“ Gemini API åˆå§‹åŒ–æˆåŠŸ (æ¨¡å‹: {self.model_name})")
        except Exception as e:
            logger.error(f"Gemini API åˆå§‹åŒ–å¤±æ•—: {str(e)}")
            self.api_available = False
            raise RuntimeError(f"ç„¡æ³•åˆå§‹åŒ– Gemini API: {str(e)}")
    
    def get_default_prompt(self, prompt_type: str) -> str:
        """
        ç²å–é è¨­æç¤ºè©
        
        Args:
            prompt_type: æç¤ºè©é¡å‹ (structure, summarize, academic)
            
        Returns:
            æç¤ºè©æ–‡å­—
        """
        return DEFAULT_PROMPTS.get(prompt_type, DEFAULT_PROMPTS["structure"])
    
    def process_text(
        self,
        text: str,
        prompt_type: str = "structure",
        custom_prompt: Optional[str] = None,
        system_instruction: Optional[str] = None
    ) -> str:
        """
        ä½¿ç”¨ Gemini è™•ç†æ–‡å­—
        
        Args:
            text: è¦è™•ç†çš„æ–‡å­—
            prompt_type: æç¤ºè©é¡å‹
            custom_prompt: è‡ªè¨‚æç¤ºè©ï¼ˆè¦†è“‹ prompt_typeï¼‰
            system_instruction: ç³»çµ±æŒ‡ä»¤
            
        Returns:
            è™•ç†å¾Œçš„æ–‡å­—
        """
        if not self.api_available:
            raise RuntimeError("Gemini API ä¸å¯ç”¨ï¼Œè«‹æª¢æŸ¥ API Key è¨­å®š")
        
        # é¸æ“‡æç¤ºè©
        if custom_prompt:
            system_prompt = custom_prompt
        else:
            system_prompt = self.get_default_prompt(prompt_type)
        
        # æ§‹å»ºå®Œæ•´æç¤º
        full_prompt = f"{system_prompt}\n\nä»¥ä¸‹æ˜¯éœ€è¦è™•ç†çš„å…§å®¹ï¼š\n\n{text}"
        
        # å¦‚æœæœ‰ç³»çµ±æŒ‡ä»¤ï¼Œä½¿ç”¨æ–°ç‰ˆ API
        if system_instruction:
            generation_config = {
                "temperature": 0.7,
                "top_p": 0.95,
                "max_output_tokens": 8192,
            }
            
            model_with_system = genai.GenerativeModel(
                self.model_name,
                system_instruction=system_instruction,
                generation_config=generation_config
            )
            
            return self._generate_with_retry(model_with_system, full_prompt)
        else:
            return self._generate_with_retry(self.model, full_prompt)
    
    def _generate_with_retry(self, model, prompt: str) -> str:
        """
        å¸¶é‡è©¦æ©Ÿåˆ¶çš„ç”Ÿæˆå‡½æ•¸
        
        Args:
            model: Gemini æ¨¡å‹å¯¦ä¾‹
            prompt: æç¤ºè©
            
        Returns:
            ç”Ÿæˆçš„æ–‡å­—
        """
        last_error = None
        
        for attempt in range(self.max_retries):
            try:
                logger.info(f"Gemini API è«‹æ±‚ (å˜—è©¦ {attempt + 1}/{self.max_retries})...")
                
                start_time = time.time()
                response = model.generate_content(prompt)
                elapsed_time = time.time() - start_time
                
                logger.info(f"âœ“ Gemini API è«‹æ±‚æˆåŠŸï¼Œè€—æ™‚ {elapsed_time:.2f} ç§’")
                
                if response.text:
                    return response.text
                else:
                    raise ValueError("Gemini API è¿”å›ç©ºå…§å®¹")
                
            except Exception as e:
                last_error = e
                logger.warning(f"Gemini API è«‹æ±‚å¤±æ•— (å˜—è©¦ {attempt + 1}): {str(e)}")
                
                if attempt < self.max_retries - 1:
                    wait_time = (attempt + 1) * 2  # æŒ‡æ•¸é€€é¿
                    logger.info(f"ç­‰å¾… {wait_time} ç§’å¾Œé‡è©¦...")
                    time.sleep(wait_time)
        
        # æ‰€æœ‰é‡è©¦éƒ½å¤±æ•—
        error_msg = f"Gemini API è«‹æ±‚å¤±æ•—ï¼ˆå·²é‡è©¦ {self.max_retries} æ¬¡ï¼‰: {str(last_error)}"
        logger.error(error_msg)
        raise RuntimeError(error_msg)
    
    def is_available(self) -> bool:
        """æª¢æŸ¥ Gemini API æ˜¯å¦å¯ç”¨"""
        return self.api_available
    
    def get_info(self) -> dict:
        """ç²å–æœå‹™è³‡è¨Š"""
        return {
            "available": self.api_available,
            "model": self.model_name,
            "max_retries": self.max_retries,
            "timeout": self.timeout
        }


# å…¨åŸŸ Gemini æœå‹™å¯¦ä¾‹
_gemini_service: Optional[GeminiService] = None


def get_gemini_service() -> GeminiService:
    """
    ç²å–æˆ–å‰µå»º Gemini æœå‹™å¯¦ä¾‹ï¼ˆå–®ä¾‹æ¨¡å¼ï¼‰
    
    Returns:
        GeminiService å¯¦ä¾‹
    """
    global _gemini_service
    
    if _gemini_service is None:
        api_key = os.getenv("GEMINI_API_KEY")
        model_name = os.getenv("GEMINI_MODEL", "gemini-2.0-flash-exp")
        max_retries = int(os.getenv("GEMINI_MAX_RETRIES", "3"))
        timeout = int(os.getenv("GEMINI_TIMEOUT", "60"))
        
        _gemini_service = GeminiService(
            api_key=api_key,
            model_name=model_name,
            max_retries=max_retries,
            timeout=timeout
        )
    
    return _gemini_service

